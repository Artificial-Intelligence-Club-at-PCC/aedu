{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a429d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded API key\n",
      "Imports successful\n",
      "Text splitting successful\n",
      "Embeddings object created\n",
      "Vectorstore created\n",
      "QA chain created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evanc\\AppData\\Local\\Temp\\ipykernel_121300\\3656116074.py:62: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: State the definition of a limit (in words)\n",
      "Result: The limit of f(x) as x approaches a is L if and only if for all epsilon greater than 0, there exists a delta greater than 0 such that 0 < |x - a| < delta implies |f(x) - L| < epsilon.\n",
      "Query: State the epsilon-delta definition of a limit for $f(x) = \\sin(\frac{1}{x})$ as $x \to 0$\n",
      "Result: The epsilon-delta definition of a limit is: $$\\lim_{x \to a} f(x) = L \\iff \forall \\epsilon > 0, \\exists \\delta > 0 \text{ such that } 0 < |x - a| < \\delta \\implies |f(x) - L| < \\epsilon$$\n",
      "\n",
      "For $f(x) = \\sin(\\frac{1}{x})$ as $x \\to 0$, the epsilon-delta definition of a limit is:\n",
      "$$\\lim_{x \\to 0} \\sin(\\frac{1}{x}) = L \\iff \\forall \\epsilon > 0, \\exists \\delta > 0 \\text{ such that } 0 < |x - 0| < \\delta \\implies |\\sin(\\frac{1}{x}) - L| < \\epsilon$$\n",
      "Query: State the sequential definition and neighborhood definitions of a limit\n",
      "Result: I am sorry, but the provided context only includes the epsilon-delta definition of a limit. It does not include the sequential or neighborhood definitions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "try:\n",
    "    with open(\"config.json\") as f:\n",
    "        config = json.load(f)\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = config[\"API_KEY\"]\n",
    "    print(\"Loaded API key\")\n",
    "except Exception as e:\n",
    "    print(\"Config/API Key Error:\", e)\n",
    "\n",
    "try:\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "    from langchain.vectorstores import Chroma\n",
    "    from langchain.text_splitter import CharacterTextSplitter\n",
    "    from langchain.chains import RetrievalQA\n",
    "    print(\"Imports successful\")\n",
    "except Exception as e:\n",
    "    print(\"Import Error:\", e)\n",
    "\n",
    "try:\n",
    "    documents = [\n",
    "        \"This is a sample document about RAG.\",\n",
    "        \"RAG combines retrieval and generation for better answers.\",\n",
    "        \"LangChain is a popular framework for building RAG systems.\",\n",
    "        \"Here is the epsilon-delta definition of a limit: $$\\lim_{x \\to a} f(x) = L \\iff \\forall \\epsilon > 0, \\exists \\delta > 0 \\text{ such that } 0 < |x - a| < \\delta \\implies |f(x) - L| < \\epsilon$$\"\n",
    "    ]\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.create_documents(documents)\n",
    "    print(\"Text splitting successful\")\n",
    "except Exception as e:\n",
    "    print(\"Text Split Error:\", e)\n",
    "\n",
    "try:\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    print(\"Embeddings object created\")\n",
    "except Exception as e:\n",
    "    print(\"Embeddings Error:\", e)\n",
    "\n",
    "try:\n",
    "    from langchain.vectorstores import FAISS\n",
    "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "    print(\"Vectorstore created\")\n",
    "except Exception as e:\n",
    "    print(\"Vectorstore Error:\", e)\n",
    "\n",
    "try:\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())\n",
    "    print(\"QA chain created\")\n",
    "except Exception as e:\n",
    "    print(\"QA Chain Error:\", e)\n",
    "\n",
    "try:\n",
    "    queries = [\n",
    "        \"State the definition of a limit (in words)\", \n",
    "        \"State the epsilon-delta definition of a limit for $f(x) = \\sin(\\frac{1}{x})$ as $x \\to 0$\", \n",
    "        \"State the sequential definition and neighborhood definitions of a limit\"\n",
    "    ]\n",
    "    for query in queries:\n",
    "        result = qa_chain.run(query)\n",
    "        print(\"Query:\", query)\n",
    "        print(\"Result:\", result)\n",
    "except Exception as e:\n",
    "    print(\"Query Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec5abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'tools', 'input'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 87\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Test the agentic RAG system with Gemini\u001b[39;00m\n\u001b[0;32m     86\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is RAG?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 87\u001b[0m result \u001b[38;5;241m=\u001b[39m agent_executor\u001b[38;5;241m.\u001b[39mrun(query)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery:\u001b[39m\u001b[38;5;124m\"\u001b[39m, query)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\evanc\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    188\u001b[0m     emit_warning()\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\evanc\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:603\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    604\u001b[0m         _output_key\n\u001b[0;32m    605\u001b[0m     ]\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    609\u001b[0m         _output_key\n\u001b[0;32m    610\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\evanc\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    188\u001b[0m     emit_warning()\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\evanc\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:386\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    379\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    384\u001b[0m }\n\u001b[1;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    387\u001b[0m     inputs,\n\u001b[0;32m    388\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[0;32m    389\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[0;32m    390\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[0;32m    391\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\evanc\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:167\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    166\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    168\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\evanc\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:155\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    150\u001b[0m     inputs,\n\u001b[0;32m    151\u001b[0m     run_id,\n\u001b[0;32m    152\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    153\u001b[0m )\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    162\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    163\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    164\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\evanc\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:287\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    285\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Missing some input keys: {'tools', 'input'}"
     ]
    }
   ],
   "source": [
    "# Cell: Implement Agentic RAG using Gemini and LangChain's AgentExecutor\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import LLMChain\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re\n",
    "\n",
    "# Define a custom prompt template for the agent\n",
    "from typing import ClassVar\n",
    "\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    template: ClassVar[str] = \"\"\"Answer the following question as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "    def format(self, **kwargs):\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        intermediate_steps = kwargs.pop(\"agent_scratchpad\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in kwargs[\"tools\"]])\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in kwargs[\"tools\"]])\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "from langchain.agents.agent import AgentOutputParser\n",
    "\n",
    "# Define a custom output parser that inherits from AgentOutputParser\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output):\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        regex = r\"Action: (.*?)[\\n]*Action Input:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            return AgentFinish(\n",
    "                return_values={\"output\": \"I could not determine the next action.\"},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2).strip(\" \").strip('\"')\n",
    "        return AgentAction(tool=action, tool_input=action_input, log=llm_output)\n",
    "\n",
    "# Define a tool for document retrieval (using the Gemini-based qa_chain)\n",
    "def retrieve_documents(query):\n",
    "    return qa_chain.run(query)\n",
    "\n",
    "tools = [Tool(name=\"RetrieveDocuments\", func=retrieve_documents, description=\"Useful for retrieving documents related to the query.\")]\n",
    "\n",
    "# Set up the agent with Gemini\n",
    "prompt = CustomPromptTemplate(template=CustomPromptTemplate.template, input_variables=[\"input\", \"agent_scratchpad\", \"tools\"])\n",
    "output_parser = CustomOutputParser()\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)  # Using the Gemini llm from the previous cell\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    allowed_tools=[tool.name for tool in tools],\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"]\n",
    ")\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Test the agentic RAG system with Gemini\n",
    "query = \"What is RAG?\"\n",
    "result = agent_executor.run(query)\n",
    "print(\"Query:\", query)\n",
    "print(\"Result:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
